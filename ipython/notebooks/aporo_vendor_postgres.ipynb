{
 "metadata": {
  "name": "",
  "signature": "sha256:748005804ef78ad7f3da2589b5dba7643e55daef336693cf64b7fd2f65b06459"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Load Libraries\n",
      "from sys import path as sys_path\n",
      "sys_path.append('/Users/admin/SERVER2/BD_Scripts/geolocation')\n",
      "from f_postgres import geoparse,ST_PREFIX_DICT,ST_SUFFIX_DICT,add_table_primary_serial_key\n",
      "from f_vendor_postgre import find_address_idx_matches\n",
      "from f_vendor_postgre import get_bldg_street_idx\n",
      "from geoCode import getGPScoord\n",
      "from re import search as re_search # re_search('pattern','string')\n",
      "from re import sub as re_sub  # re_sub('pattern','repl','string','count')\n",
      "\n",
      "from time import sleep\n",
      "from pygeocoder import Geocoder\n",
      "from shapely.geometry import Point\n",
      "import pandas as pd\n",
      "pd.set_option('display.max_rows', 1000)\n",
      "from sqlalchemy import create_engine\n",
      "engine = create_engine(r'postgresql://postgres:postgres@localhost/routing',\n",
      "                       encoding='utf-8',\n",
      "                       echo=False)\n",
      "\n",
      "BASE_SAVE_PATH = '/Users/admin/Projects/GIS/table_data/'"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### Pull Vendor Data\n",
      "f='/Users/admin/SERVER2/BD_Scripts/RD/RD-seth/NYC-addresses.csv'\n",
      "df = pd.read_csv(f)\n",
      "df = df.ix[:,['Vendor #','addr_num','addr_street','address','zipcode','Lat.','Long.']]\n",
      "df.rename(columns={'Vendor #':'seam_id',\n",
      "                   'Lat.':'lat',\n",
      "                   'Long.':'lon'},inplace=True)\n",
      "df['clean_addr'] = df.address.map(lambda s: s.decode('latin-1').encode('utf8', 'replace'))\n",
      "df['addr_num']=df.clean_addr.map(lambda s: s[:s.find(' ')].strip())\n",
      "df['addr_street']=df.clean_addr.map(lambda s: s[s.find(' ')+1:].strip())\n",
      "df = df.drop(['address','clean_addr','lat','lon'],axis=1)\n",
      "df = geoparse(df,'addr_street','addr_street')\n",
      "df_uniq_st = df.addr_street.unique().tolist()\n",
      "ur,r,TCL = get_bldg_street_idx( df,\n",
      "                                addr_num_col='addr_num',\n",
      "                                addr_street_col='addr_street',\n",
      "                                zipcode_col='zipcode',\n",
      "                                show_info=False)\n",
      "print len(df),'TOTAL addresses from CSV\\n'+str(len(df_uniq_st)),'unique ways'\n",
      "print len(ur),'recognized ways ( ',round(100*float(len(ur)/float(len(df_uniq_st))),2),'% )\\n'\n",
      "print 'ur:r:TCL',str(len(ur))+':'+str(len(r))+':'+str(len(TCL))\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'pd' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-3283f9e57a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/admin/SERVER2/BD_Scripts/RD/RD-seth/NYC-addresses.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vendor #'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'addr_num'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'addr_street'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'zipcode'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Lat.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Long.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df.rename(columns={'Vendor #':'seam_id',\n\u001b[1;32m      5\u001b[0m                    \u001b[0;34m'Lat.'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get Nodes for Matched Street Names\n",
      "\n",
      "ur['good'] = False\n",
      "ur['good'] = ur.ix[:,['zipcode',\n",
      "                    'bldg_street_idx',\n",
      "                    'addr_num']].apply(lambda s: True if ( (s[0].isdigit())&\n",
      "                                                          (s[1].isdigit())&\n",
      "                                                          (s[2].isdigit()) ) else False,axis=1)\n",
      "good_idx = ur[ur.good==True].index\n",
      "m = ur.ix[good_idx,:]\n",
      "m['idx'] = m.ix[:,\n",
      "          ['bldg_street_idx','addr_num']\n",
      "          ].apply(lambda s: str(s[0])+'.'+str('%05d'%eval(s[1])),axis=1)\n",
      "\n",
      "from_lbl,to_lbl='idx','geom'\n",
      "T = {'1':str(m[from_lbl].tolist()),\n",
      "     '2':from_lbl,\n",
      "     '3':to_lbl}\n",
      "cmd = \"\"\"\n",
      "    SELECT %(2)s, l.geom %(3)s\n",
      "    FROM lot_pts l\n",
      "    INNER JOIN unnest(array[%(1)s]) %(2)s\n",
      "    ON to_number(%(2)s,'00000D00000') <= l.lot_idx_end\n",
      "    WHERE l.lot_idx_start <= to_number(%(2)s,'99999D99999')\n",
      "    \"\"\".replace('\\n',' ') % T\n",
      "# print cmd\n",
      "matched_res = pd.read_sql_query(cmd,engine)\n",
      "matched_res_idx_list = matched_res.idx.tolist()\n",
      "pd.merge(left=m[m.idx.isin(matched_res_idx_list)],right=matched_res,\n",
      "         how='left',on='idx')\n",
      "\n",
      "idx_geom_map = dict(zip(matched_res_idx_list,matched_res.geom.tolist()))\n",
      "\n",
      "print len(matched_res),'matched lots'\n",
      "print matched_res.head()"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get Nodes for Unmatched Street Names\n",
      "\n",
      "### Identify matched street names but unmatched lots\n",
      "res_idx = matched_res.idx.tolist()\n",
      "z = m[m.idx.isin(res_idx)==False]\n",
      "z = z.drop(['good'],axis=1)\n",
      "print len(z),'unmatched lots'\n",
      "\n",
      "### Combine remaining addresses to be located\n",
      "R = r.append(TCL,ignore_index=True)\n",
      "R['idx'] = None\n",
      "R = R.append(z,ignore_index=True)\n",
      "R = R.drop(['norm_addr_num','norm_addr','body'],axis=1)\n",
      "print len(R),'total unmatched addr.s'\n",
      "print R.head()\n",
      "\n",
      "### Run Google Geocode for Non-Street Name Matches\n",
      "all_addr = R.full_address.unique().tolist()\n",
      "d = getGPScoord(all_addr,printGPS=False,savePath='',)\n",
      "\n",
      "matched_addr = d[d.res_i==-1]\n",
      "merged_res = pd.merge(left=R,right=matched_addr,how='left',left_on='full_address',right_on='orig_addr')\n",
      "\n",
      "addr_to_check = d.ix[d.index-matched_addr.index,:]\n",
      "addr_to_check_list = addr_to_check.orig_addr.tolist()\n",
      "\n",
      "merged_res = merged_res[merged_res.full_address.isin(addr_to_check_list)==False].reset_index(drop=True)\n",
      "\n",
      "### Copy g_matched vars to g_coded table, which will be incorporated into initial search \n",
      "u_res = unmatched_res = merged_res.drop(['seam_id','addr_num','addr_street','zipcode','full_address',\n",
      "                 'addr_valid','res_i'],axis=1)\n",
      "u_res['tmp'] = u_res.geometry.map(lambda s: 'POINT(%(lat)f %(lng)f)' % s['location'])\n",
      "u_res['res_data'] = u_res.res_data.map(lambda s: str(s).replace(\"u'\",'\"').replace(\"'\",'\"'))\n",
      "\n",
      "engine.execute('drop table if exists g_coded')\n",
      "cmd = \"\"\"\n",
      "create table g_coded (\n",
      "    bldg_street_idx text,\n",
      "    idx text,\n",
      "    form_addr text,\n",
      "    orig_addr text,\n",
      "    partial_match text,\n",
      "    res_data text,\n",
      "    tmp text,\n",
      "    geom geometry(Point,4326)\n",
      ");\n",
      "\"\"\"\n",
      "engine.execute(cmd)\n",
      "u_res.drop(['geometry','lat','lon'],axis=1).to_sql(\"g_coded\",engine,if_exists='append',index=False)\n",
      "add_table_primary_serial_key('g_coded','id')\n",
      "engine.execute(\"update g_coded set geom = ST_GeomFromText(tmp,4326)\")"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### Combine Nodes and Save to \"vendors\"\n",
      "first_matched = matched_res.copy()\n",
      "\n",
      "idx_seam_id_map = dict(zip(m.idx.tolist(),m.seam_id.tolist()))\n",
      "first_matched['seam_id'] = first_matched.idx.map(idx_seam_id_map)\n",
      "seam_id_full_address_map = dict(zip(m.seam_id.tolist(),m.full_address.tolist()))\n",
      "first_matched['full_address'] = first_matched.seam_id.map(seam_id_full_address_map)\n",
      "first_matched = first_matched.ix[:,['seam_id','full_address','geom']]\n",
      "\n",
      "# second_matched_idx = \n",
      "second_m = R.copy()#m.ix[second_matched_idx,:]\n",
      "addr_seam_id_map = dict(zip(second_m.full_address.tolist(),second_m.seam_id.tolist()))\n",
      "second_matched = pd.read_sql_query(\"select 0 seam_id,orig_addr full_address,geom from g_coded where tmp is not null\",engine)\n",
      "# engine.execute(\"update g_coded set tmp = null\")\n",
      "second_matched['seam_id'] = second_matched.full_address.map(addr_seam_id_map)\n",
      "second_matched = second_matched.ix[:,['seam_id','full_address','geom']]\n",
      "\n",
      "new_queue = first_matched.append(second_matched,ignore_index=True)\n",
      "print len(new_queue)\n",
      "new_queue\n",
      "engine.execute('drop table if exists vendors')\n",
      "cmd = \"\"\"\n",
      "create table vendors (\n",
      "    index integer,\n",
      "    seam_id integer,\n",
      "    full_address text,\n",
      "    geom geometry(Point,4326)\n",
      ");\n",
      "\"\"\"\n",
      "engine.execute(cmd)\n",
      "print len(new_queue)\n",
      "print new_queue.head()\n",
      "new_queue.to_sql(\"vendors\",engine,if_exists='append',index=False)\n",
      "add_table_primary_serial_key('vendors','id')"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "332\n",
        "   seam_id                       full_address  \\\n",
        "0    29378  33 leonard st, New York, NY 10013   \n",
        "1     4182  349 greenwich, New York, NY 10013   \n",
        "2    24077  505 broome st, New York, NY 10013   \n",
        "3    11483    2 rector st, New York, NY 10006   \n",
        "4     3445    262 bleeker, New York, NY 10012   \n",
        "\n",
        "                                                geom  \n",
        "0  0101000020E6100000B8F674AB768052C0A35DD00BF35B...  \n",
        "1  0101000020E61000001A49C6E2AA8052C032757B47FD5B...  \n",
        "2  0101000020E610000080943C812E8052C07B462B2B945C...  \n",
        "3  0101000020E6100000E76A1E39D68052C0A39E5561995A...  \n",
        "4  0101000020E61000001E76BD1F338052C0376036C59F5D...  \n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "#Need to:\n",
      "1. use translate method\n",
      "2. have google backup (pay now for high-volume availability?)\n",
      "3. be able use gps to locate point on mn_ways\n",
      "4. add node to db\n",
      "5. simply mn_ways_vertices_pgr\n",
      "6. retrieve distances for multi-dijkstra\n",
      "\n",
      "##To Do:\n",
      "\n",
      "\n",
      "1. google api (note for geopy) for remainder \n",
      "    - error goes to me\n",
      "2. code all addresses for nodes\n",
      "\n",
      "\n",
      "3. create layer of nodes from addresses\n",
      "\n",
      "\n",
      "4. find all distances between them\n",
      "\n",
      "\n",
      "    - get all permutations for a set of two points\n",
      "\n",
      "\n",
      "5. as the orders come in, assign them to dg with smallest effect on current route (i.e., least add'l time)\n",
      "\n",
      "\n",
      "6. for each round: take lowest order/min as candidates for redistribution\n",
      "\n",
      "\n",
      "    - option is always available for pooling improv. plugin\n",
      "\n",
      "\n",
      "7. for segments along path with most overlapping area, consider switching close points and keep switch if improv.\n",
      "\n",
      "\n",
      "8. in all cases, order MUST be committed before available DG are None.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}