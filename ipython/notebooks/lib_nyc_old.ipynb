{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "name": "",
  "signature": "sha256:22d68e54ee9670fdaddb09ad9035651dacde2ce15b55db2c08a9dff721b3fae2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "TODO:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Turn Stile Data:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "GOAL -- For Dates A to B and Times C to D, how many people per station?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. consolidate scp's per remote/booth\n",
      "\n",
      "    Thoughts:\n",
      "        - each scp has its own range of timestamps and register values\n",
      "        - some scp.s have multiple datasets for same time period\n",
      "        - timestamps exists for all times of the day\n",
      "        \n",
      "    Method:\n",
      "        - create new table with:\n",
      "            - date column\n",
      "            - 24 columns for each hour filled with register-change values\n",
      "                - need 24 or just use single time col?\n",
      "            - index # from sub_turn_stiles\n",
      "            \n",
      "        \n",
      "\n",
      "2. consolidate remote/booth per station"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sql postgres@routing\n",
      "select distinct extract(hour from datetime1) s\n",
      "from sub_turn_stiles\n",
      "order by s"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### Using PostgresSQL Server [ db1.public.routing ]:\n",
      "\n",
      "from sys import path as sys_path\n",
      "from f_postgres import make_index,geom_inside_street_box,make_column_primary_serial_key\n",
      "from re import search as re_search # re_search('pattern','string')\n",
      "from re import sub as re_sub  # re_sub('pattern','repl','string','count')\n",
      "\n",
      "import pandas as pd\n",
      "pd.set_option('expand_frame_repr',False)\n",
      "pd.set_option('display.max_columns', None)\n",
      "pd.set_option('display.max_rows', 1000)\n",
      "pd.set_option('display.width',180)\n",
      "np = pd.np\n",
      "np.set_printoptions(linewidth=400,threshold=np.nan)\n",
      "import geopandas as gd\n",
      "from types import NoneType\n",
      "from time import sleep as delay\n",
      "from sqlalchemy import create_engine\n",
      "from logging import getLogger\n",
      "from logging import INFO as logging_info\n",
      "getLogger('sqlalchemy.dialects.postgresql').setLevel(logging_info)\n",
      "\n",
      "engine = create_engine(r'postgresql://postgres:postgres@localhost:8800/routing',\n",
      "                       encoding='utf-8',\n",
      "                       echo=False)\n",
      "\n",
      "%load_ext sql\n",
      "%sql postgresql://postgres:postgres@localhost/routing"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### add restaurant data\n",
      "import requests, zipfile, StringIO\n",
      "# from f_postgres import geoparse\n",
      "z = requests.get('https://data.cityofnewyork.us/download/4vkw-7nck/ZIP')\n",
      "r = zipfile.ZipFile(StringIO.StringIO(z.content))\n",
      "v = pd.read_csv(r.open('WebExtract.txt'))\n",
      "v.columns = [ str(it).lower() for it in v.columns.tolist() ]\n",
      "m = v[v.boro==1].copy()\n",
      "m['inspdate'] = pd.to_datetime(m.inspdate)\n",
      "m = m.sort('inspdate',ascending=False).reset_index(drop=True)\n",
      "z = m.groupby('camis')\n",
      "grps = z.groups.keys()\n",
      "takeCols = ['dba','cuisinecode','building','street','zipcode','phone','inspdate'] # and 'camis' which is the grps[i]\n",
      "mv = pd.DataFrame(columns=['camis']+takeCols)\n",
      "g_cnt = len(grps)\n",
      "for i in range(g_cnt):\n",
      "    vend_id = grps[i]\n",
      "    x = z.get_group(vend_id).reset_index(drop=True).ix[0,takeCols]\n",
      "    x['camis'] = vend_id\n",
      "    mv = mv.append(x)\n",
      "mv = geoparse(mv,'dba','clean_name')\n",
      "mv = geoparse(mv,'street','clean_street')\n",
      "mv['dba'] = mv.dba.map(lambda s: s.decode('ascii','ignore').encode('utf-8','ignore'))\n",
      "engine.execute('drop table if exists mn_vendors')\n",
      "mv.to_sql('mn_vendors',engine,index=False)\n",
      "engine.execute(\"\"\"\n",
      "    alter table mn_vendors add column id serial;\n",
      "    update mn_vendors set id = nextval(pg_get_serial_sequence('mn_vendors','id'));\n",
      "    alter table mn_vendors add primary key (id);\n",
      "    \"\"\")\n",
      "engine.execute(\"\"\"alter table mn_vendors add column recog_street boolean;\n",
      "                  update mn_vendors set recog_street = False;\"\"\")\n",
      "engine.execute(\"\"\"  update mn_vendors set recog_street = True\n",
      "                    where exists (\n",
      "                        select 1 from address_idx a\n",
      "                        where a.street = clean_street\n",
      "                    )\"\"\")"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ]
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### add subway entrances to map\n",
      "url = 'http://web.mta.info/developers/data/nyct/subway/StationEntrances.csv'\n",
      "s = pd.read_csv(url)\n",
      "s.columns = [it.lower().strip() for it in s.columns.tolist()]\n",
      "engine.execute('drop table if exists sub_stat_entr')\n",
      "s.to_sql('sub_stat_entr',engine)\n",
      "engine.execute('alter table sub_stat_entr add column geom geometry(Point,4326)')\n",
      "engine.execute(\"\"\"UPDATE sub_stat_entr set geom = ST_SetSRID(ST_MakePoint(station_longitude,station_latitude),4326)\"\"\")\n",
      "engine.execute(\"\"\" DELETE FROM sub_stat_entr \n",
      "                WHERE NOT (geom && (\n",
      "                    SELECT ST_Buffer(ST_ConvexHull((ST_Collect(f.the_geom))), .0005) as geom \n",
      "                    FROM ( SELECT *, (ST_Dump(geom)).geom As the_geom \n",
      "                    FROM pluto) As f))\"\"\")\n",
      "engine.execute(\"\"\"\n",
      "    alter table sub_stat_entr add column id serial;\n",
      "    update sub_stat_entr set index = nextval(pg_get_serial_sequence('sub_stat_entr','id'));\n",
      "    alter table sub_stat_entr add primary key (id);\n",
      "    \"\"\")"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### add subway stops to map, add turn stile data to subway stops\n",
      "import requests, zipfile, StringIO\n",
      "r = requests.get('http://web.mta.info/developers/data/nyct/subway/google_transit.zip')\n",
      "z = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
      "sub_stops = pd.read_csv(z.open('stops.txt'))\n",
      "sub_stops.to_sql('sub_stops',engine)\n",
      "engine.execute('alter table sub_stops add column geom geometry(Point,4326)')\n",
      "engine.execute(\"\"\"UPDATE sub_stops set geom = ST_SetSRID(ST_MakePoint(stop_lon,stop_lat),4326)\"\"\")\n",
      "engine.execute(\"\"\" DELETE FROM sub_stops \n",
      "                WHERE NOT (geom && (\n",
      "                    SELECT ST_Buffer(ST_ConvexHull((ST_Collect(f.the_geom))), .0005) as geom \n",
      "                    FROM ( SELECT *, (ST_Dump(geom)).geom As the_geom \n",
      "                    FROM pluto) As f))\"\"\")\n",
      "engine.execute(\"\"\"\n",
      "    alter table sub_stops add column id serial;\n",
      "    update sub_stops set index = nextval(pg_get_serial_sequence('sub_stops','id'));\n",
      "    alter table sub_stops add primary key (id);\n",
      "    \"\"\")\n",
      "# NOTE:  also then deleted more by hand"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### add turn_stile_key to pgsql\n",
      "ts_key = pd.read_excel('http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls')\n",
      "ts_key.columns = [str(it).lower().replace(' ','_') for it in ts_key.columns.tolist()]\n",
      "ts_key['line_name'] = ts_key['line_name'].map(lambda s: ''.join(sorted([str(it) for it in s])) if type(s)!=int else str(s))\n",
      "ts_key['clean'] = ts_key.station.map(lambda s: s.lower())\n",
      "engine.execute(\"drop table if exists ts_key\")\n",
      "ts_key.to_sql('ts_key',engine)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### add turn stile data to pgsql\n",
      "# General Source for Turn Stiles: http://web.mta.info/developers/turnstile.html\n",
      "#     - field description: http://web.mta.info/developers/resources/nyct/turnstile/ts_Field%20Description.txt\n",
      "#     - data key: http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls\n",
      "#         --> this is the provides the Remote Unit/Control Area/Station Name Key\n",
      "# Need coords for \"UNIT\"\n",
      "# Remote and Station Name here:\n",
      "#      'http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls'\n",
      "# Station Names and Coords here:\n",
      "#      'http://web.mta.info/developers/data/nyct/subway/StationEntrances.csv'\n",
      "#     - Relevant stations were added to pgsql as 'sub_stat_entr'\n",
      "\n",
      "\n",
      "cols = ['C/A','UNIT','SCP','DATE1','TIME1','DESC1','ENTRIES1','EXITS1',\n",
      "        'DATE2','TIME2','DESC2','ENTRIES2','EXITS2','DATE3','TIME3','DESC3','ENTRIES3',\n",
      "        'EXITS3','DATE4','TIME4','DESC4','ENTRIES4','EXITS4','DATE5','TIME5','DESC5',\n",
      "        'ENTRIES5','EXITS5','DATE6','TIME6','DESC6','ENTRIES6',\n",
      "        'EXITS6','DATE7','TIME7','DESC7','ENTRIES7','EXITS7','DATE8',\n",
      "        'TIME8','DESC8','ENTRIES8','EXITS8']\n",
      "cols = [str(it).lower().replace('/','_') for it in cols]\n",
      "url = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_141004.txt'\n",
      "p = pd.read_csv(url,names=cols)\n",
      "idx = p[p.unit.str.contains('R')==False].index\n",
      "p = p.drop(idx,axis=0).reset_index(drop=True)\n",
      "# ts_key = pd.read_excel('http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls')\n",
      "# ts_key.columns = [str(it).lower().replace(' ','_') for it in ts_key.columns.tolist()]\n",
      "\n",
      "dropCols = []\n",
      "for it in cols:\n",
      "    if it.find('exit')==0 or it.find('entries')==0:\n",
      "        p[it] = p[it].map(float)\n",
      "    if it.find('date')==0:\n",
      "        date_pt,time_pt,datetime_pt = it,'time'+it[4:],'datetime'+it[4:]\n",
      "        p[datetime_pt] = pd.to_datetime(p[date_pt] + ' ' + p[time_pt],format='%m-%d-%y %H:%M:%S',coerce=False)\n",
      "        p[datetime_pt] = p[datetime_pt].map(lambda s: None if str(s)=='NaT' else str(s))\n",
      "        dropCols.extend([date_pt,time_pt])\n",
      "p = p.drop(dropCols,axis=1)\n",
      "cols = p.columns.tolist()\n",
      "\n",
      "# END GOAL conform 'station_names' to 'mn_stations'\n",
      "mn_stations = pd.read_sql(\"\"\"select * from sub_stat_entr\"\"\",engine)\n",
      "\n",
      "# Limit NYC key to MN\n",
      "mn_div_list = mn_stations.division.unique().tolist()\n",
      "ts_key = ts_key.drop(ts_key[ts_key.division.isin(mn_div_list)==False].index,axis=0)\n",
      "\n",
      "# Create and Sort Route List for each station\n",
      "mn_cols = mn_stations.columns.tolist()\n",
      "s_pt,e_pt = mn_cols.index('route_1'),mn_cols.index('route_11')+1\n",
      "mn_stations['all_lines'] = mn_stations.ix[:,s_pt:e_pt].apply(lambda s: ''.join([str(it) for it in s if str(it)!='NaN']).replace('nan','').replace('.0',''),axis=1)\n",
      "mn_stations['all_lines'] = mn_stations.all_lines.map(lambda s: ''.join(sorted(s)))\n",
      "# ts_key['line_name'] = ts_key['line_name'].map(lambda s: ''.join(sorted([str(it) for it in s])) if type(s)!=int else str(s))\n",
      "\n",
      "# clean up many but small differences between station names\n",
      "mn_stations['clean'] = mn_stations.station_name.map(lambda s: s.lower())\n",
      "# ts_key['clean'] = ts_key.station.map(lambda s: s.lower())\n",
      "repl_dict = {   r'(1st|first)'          :r'1',\n",
      "                r'(2nd|second)'         :r'2',\n",
      "                r'(3rd|third)'          :r'3',\n",
      "                r'(4th|fourth)'         :r'4',\n",
      "                r'(5th|fifth)'          :r'5',\n",
      "                r'(6th|sixth)'          :r'6',\n",
      "                r'(7th|seventh)'        :r'7',\n",
      "                r'(8th|eigth)'          :r'8',\n",
      "                r'(9th|nineth|ninth)'   :r'9',\n",
      "                r'(0th)'                :r'0',\n",
      "                r'(1th)'                :r'1',\n",
      "                r'(2th)'                :r'2',\n",
      "                r'(3th)'                :r'3',\n",
      "                r'\\s(street)'           :r' st',\n",
      "                r'\\s(square)'           :r' sq',\n",
      "                r'\\s(center)'           :r' ctr',\n",
      "                r'\\s(av)':r' ave'}\n",
      "for k,v in repl_dict.iteritems():\n",
      "    mn_stations['clean'] = mn_stations.clean.str.replace(k,v)\n",
      "    \n",
      "repl_dict = {   r'\\Aunion sq':r'14 st-union sq',\n",
      "                r'cathedral parkway-110 st':r'110 st-cathedrl',\n",
      "                r'163 st - amsterdam ave':r'163 st-amsterdm',\n",
      "                r'81 st - museum of natural history':r'81 st-museum',\n",
      "                r'47-50 sts rockefeller ctr':r'47-50 st-rock',\n",
      "                r'137 st-city college':r'137 st-city col',\n",
      "                r'broadway-lafayette st':r'broadway/lafay',\n",
      "                r'west 4 st':r'w 4 st-wash sq' ,\n",
      "                r'110 st-central park north':r'110 st-cpn',\n",
      "                r'116 st-columbia university':r'116 st-columbia',\n",
      "                r'168 st - washington heights':r'168 st-broadway',\n",
      "#                 r'168 st-broadway - washington heights':r'168 st-broadway',\n",
      "                r'49 st':r'49 st-7 ave',\n",
      "                r'168 st\\Z':r'168 st-broadway',\n",
      "                r'59 st-columbus circle':r'59 st-columbus',\n",
      "                r'66 st-lincoln ctr':r'66 st-lincoln',\n",
      "                r'68 st-hunter college':r'68st-hunter col',\n",
      "                # r'astor pl':'astor place',\n",
      "                r'brooklyn bridge-city hall':r'brooklyn bridge',\n",
      "                r'dyckman st-200 st':r'dyckman-200 st',\n",
      "                r'grand central-42 st':r'42 st-grd cntrl',\n",
      "                r'inwood - 207 st':r'inwood-207 st',\n",
      "                r'lexington av-53 st':r'lexington-53 st',\n",
      "                r'prince st':r\"prince st-b'way\",\n",
      "                r'\\Atimes sq\\Z':r'42 st-times sq',\n",
      "                r'times sq-42 st':r'42 st-times sq',\n",
      "                r'van cortlandt park-242 st':r'242 st',\n",
      "                r'marble hill-225 st':r'225 st',\n",
      "                r'lexington ave-53 st':r'lexington-53 st',\n",
      "                r'harlem-148 st':r'148 st-lenox',\n",
      "                r'\\Agrand central\\Z':r'42 st-grd cntrl',\n",
      "                r'\\Acanal st (ul)\\Z':r'canal st',}\n",
      "for k,v in repl_dict.iteritems():\n",
      "    mn_stations['clean'] = mn_stations.clean.str.replace(k,v)\n",
      "\n",
      "station_names = ts_key.clean.tolist()\n",
      "#print len(mn_stations[mn_stations.clean.isin(station_names)==False]), 'stations not mapped'\n",
      "# mn_stations[mn_stations.clean.isin(station_names)==False].ix[:,['division','line','station_name','all_lines','clean']].sort('clean')\n",
      "# mn_stations.head()\n",
      "\n",
      "# push to [ sub_stat_entr,ts_key,p(turn stiles) ] to pgsql for comparison and unificiation\n",
      "engine.execute('drop table if exists sub_stat_entr')\n",
      "engine.execute('drop table if exists ts_key')\n",
      "engine.execute('drop table if exists sub_turn_stiles')\n",
      "delay(1)\n",
      "\n",
      "mn_stations.drop(['id','index'],axis=1).to_sql('sub_stat_entr',engine)\n",
      "engine.execute(\"\"\"\n",
      "    alter table sub_stat_entr add column id serial;\n",
      "    update sub_stat_entr set index = nextval(pg_get_serial_sequence('sub_stat_entr','id'));\n",
      "    alter table sub_stat_entr add primary key (id);\n",
      "    \"\"\")\n",
      "engine.execute(\"\"\"UPDATE sub_stat_entr set geom = ST_SetSRID(ST_MakePoint(station_longitude,station_latitude),4326)\"\"\")\n",
      "\n",
      "# ts_key.to_sql('ts_key',engine)\n",
      "engine.execute(\"\"\"\n",
      "    alter table ts_key add column lat double precision;\n",
      "    alter table ts_key add column lon double precision;\n",
      "    alter table ts_key add column id serial;\n",
      "    update ts_key set index = nextval(pg_get_serial_sequence('ts_key','id'));\n",
      "    alter table ts_key add primary key (id);\n",
      "    \"\"\")\n",
      "\n",
      "p.to_sql('sub_turn_stiles',engine)\n",
      "engine.execute(\"\"\"\n",
      "    alter table sub_turn_stiles add column station text;\n",
      "    alter table sub_turn_stiles add column lat double precision;\n",
      "    alter table sub_turn_stiles add column lon double precision;\n",
      "    alter table sub_turn_stiles add column id serial;\n",
      "    update sub_turn_stiles set index = nextval(pg_get_serial_sequence('sub_turn_stiles','id'));\n",
      "    alter table sub_turn_stiles add primary key (id);\n",
      "    \"\"\")\n",
      "\n",
      "# 1. Copy coords from station_entrances to turnstile_key\n",
      "engine.execute( \"\"\"\n",
      "                UPDATE ts_key t\n",
      "                SET lat = s.station_latitude,lon = s.station_longitude\n",
      "                FROM sub_stat_entr s\n",
      "                WHERE s.clean=t.clean\n",
      "                AND s.all_lines=t.line_name;\n",
      "                \"\"\")\n",
      "#print pd.read_sql('select count(*) c from ts_key where lon is null',engine).c[0],'null'\n",
      "#print pd.read_sql('select count(*) c from ts_key where lon is not null',engine).c[0],'not null'\n",
      "\n",
      "# 2. Copy matching ts_key table data to turn_stiles table\n",
      "engine.execute( \"\"\"\n",
      "                UPDATE sub_turn_stiles\n",
      "                SET lat = t.lat,lon=t.lon,station=t.station\n",
      "                FROM ts_key t\n",
      "                WHERE t.remote = unit\n",
      "                AND t.booth = c_a;\n",
      "                \"\"\")\n",
      "engine.execute('alter table sub_turn_stiles add column geom geometry(Point,4326)')\n",
      "engine.execute(\"\"\"UPDATE sub_turn_stiles set geom = ST_SetSRID(ST_MakePoint(lon,lat),4326)\"\"\")\n",
      "\n",
      "# 3. Attempt to match leftovers (non-matching) b/t ts_key/sub_stat_entr using wildcards\n",
      "leftovers = pd.read_sql(\"select * from ts_key where lon is null and division = any(array['IRT','IND','BMT'])\",engine)\n",
      "for i in range(0,len(leftovers)):\n",
      "    row = leftovers.ix[i,:]\n",
      "    chk = row['clean'].find('-')\n",
      "    if chk != -1:\n",
      "        a,b = '%%'+str(row['clean'].split('-')[0])+'%%',row['line_name']\n",
      "        tmp = pd.read_sql(  \"\"\" \n",
      "                            SELECT station_latitude lat,station_longitude lon\n",
      "                            FROM sub_stat_entr s\n",
      "                            WHERE s.clean ilike '%s'\n",
      "                            AND s.all_lines='%s';\n",
      "                            \"\"\"%(a,b),engine)\n",
      "        if (len(tmp.lat.unique())==len(tmp.lat.unique())==1):\n",
      "            a,b,c = tmp.lat[0],tmp.lon[0],row['id']\n",
      "            engine.execute( \"\"\"\n",
      "                                UPDATE ts_key set lat=%f,lon=%f\n",
      "                                WHERE id = %d\n",
      "                            \"\"\"%(a,b,c),engine)\n",
      "            \n",
      "# 4. Attempt to match leftover by:\n",
      "        # starting with lines,division, \n",
      "            # if one result go with it, \n",
      "            # else if only one result and it's a partial match, go with it?\n",
      "leftovers = pd.read_sql(\"select * from ts_key where lon is null and division = any(array['IRT','IND','BMT'])\",engine)\n",
      "for i in range(0,len(leftovers)):\n",
      "    row = leftovers.ix[i,:]\n",
      "    a,b,c = '%%'+str(row['clean'].split('-')[0])+'%%',row['line_name'],row['division']\n",
      "    tmp = pd.read_sql(  \"\"\" \n",
      "                        SELECT station_latitude lat,station_longitude lon,clean\n",
      "                        FROM sub_stat_entr s\n",
      "                        WHERE s.division='%s'\n",
      "                        AND s.all_lines='%s';\n",
      "                        \"\"\"%(c,b),engine)\n",
      "    if (len(tmp.lat.unique())==len(tmp.lat.unique())==1):\n",
      "        a,b,c = tmp.lat[0],tmp.lon[0],row['id']\n",
      "        engine.execute( \"\"\"\n",
      "                            UPDATE ts_key set lat=%f,lon=%f\n",
      "                            WHERE id = %d\n",
      "                        \"\"\"%(a,b,c),engine)\n",
      "    else:\n",
      "        z=tmp[tmp.clean.str.contains(a)]\n",
      "        if (len(z.lat.unique())==len(z.lat.unique())==1):\n",
      "            a,b,c = tmp.lat[0],tmp.lon[0],row['id']\n",
      "            engine.execute( \"\"\"\n",
      "                                UPDATE ts_key set lat=%f,lon=%f\n",
      "                                WHERE id = %d\n",
      "                            \"\"\"%(a,b,c),engine)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# TURN STILE CONT'D convert text to timestamp\n",
      "\n",
      "engine.execute(\"\"\"  \n",
      "\n",
      "    DROP TABLE if exists tmp;\n",
      "\n",
      "    CREATE TABLE tmp (\n",
      "        gid serial primary key,\n",
      "        datetime1 timestamp with time zone,\n",
      "        datetime2 timestamp with time zone,\n",
      "        datetime3 timestamp with time zone,\n",
      "        datetime4 timestamp with time zone,\n",
      "        datetime5 timestamp with time zone,\n",
      "        datetime6 timestamp with time zone,\n",
      "        datetime7 timestamp with time zone,\n",
      "        datetime8 timestamp with time zone\n",
      "        );\n",
      "\n",
      "    UPDATE tmp SET gid = nextval(pg_get_serial_sequence('tmp','gid'));\n",
      "\n",
      "    INSERT INTO tmp (\n",
      "        datetime1,\n",
      "        datetime2,\n",
      "        datetime3,\n",
      "        datetime4,\n",
      "        datetime5,\n",
      "        datetime6,\n",
      "        datetime7,\n",
      "        datetime8)\n",
      "    SELECT \n",
      "        to_timestamp(s.datetime1,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime2,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime3,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime4,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime5,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime6,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime7,'YYYY-MM-DD HH24:MI:SS'),\n",
      "        to_timestamp(s.datetime8,'YYYY-MM-DD HH24:MI:SS')\n",
      "    FROM sub_turn_stiles s;\n",
      "\n",
      "    ALTER TABLE sub_turn_stiles \n",
      "    DROP COLUMN datetime1,\n",
      "    DROP COLUMN datetime2,\n",
      "    DROP COLUMN datetime3,\n",
      "    DROP COLUMN datetime4,\n",
      "    DROP COLUMN datetime5,\n",
      "    DROP COLUMN datetime6,\n",
      "    DROP COLUMN datetime7,\n",
      "    DROP COLUMN datetime8,\n",
      "    ADD COLUMN datetime1 timestamp with time zone,\n",
      "    ADD COLUMN datetime2 timestamp with time zone,\n",
      "    ADD COLUMN datetime3 timestamp with time zone,\n",
      "    ADD COLUMN datetime4 timestamp with time zone,\n",
      "    ADD COLUMN datetime5 timestamp with time zone,\n",
      "    ADD COLUMN datetime6 timestamp with time zone,\n",
      "    ADD COLUMN datetime7 timestamp with time zone,\n",
      "    ADD COLUMN datetime8 timestamp with time zone;\n",
      "\n",
      "    UPDATE sub_turn_stiles s\n",
      "    SET \n",
      "        datetime1 = t.datetime1,\n",
      "        datetime2 = t.datetime2,\n",
      "        datetime3 = t.datetime3,\n",
      "        datetime4 = t.datetime4,\n",
      "        datetime5 = t.datetime5,\n",
      "        datetime6 = t.datetime6,\n",
      "        datetime7 = t.datetime7,\n",
      "        datetime8 = t.datetime8\n",
      "    FROM tmp t\n",
      "    where t.gid = s.id;\n",
      "\n",
      "               \"\"\")"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# TURN STILE CONT'D calc. register differences\n",
      "engine.execute(\"\"\"\n",
      "alter table sub_turn_stiles \n",
      "add column out1 double precision,\n",
      "add column out2 double precision,\n",
      "add column out3 double precision,\n",
      "add column out4 double precision,\n",
      "add column out5 double precision,\n",
      "add column out6 double precision,\n",
      "add column out7 double precision,\n",
      "add column in1 double precision,\n",
      "add column in2 double precision,\n",
      "add column in3 double precision,\n",
      "add column in4 double precision,\n",
      "add column in5 double precision,\n",
      "add column in6 double precision,\n",
      "add column in7 double precision;\n",
      "\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out1 = exits2-exits1\n",
      "where exits1 != 'NaN'::float\n",
      "and exits2 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out2 = exits3-exits2\n",
      "where exits2 != 'NaN'::float\n",
      "and exits3 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out3 = exits4-exits3\n",
      "where exits3 != 'NaN'::float\n",
      "and exits4 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out4 = exits5-exits4\n",
      "where exits4 != 'NaN'::float\n",
      "and exits5 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out5 = exits6-exits5\n",
      "where exits5 != 'NaN'::float\n",
      "and exits6 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out6 = exits7-exits6\n",
      "where exits6 != 'NaN'::float\n",
      "and exits7 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set out7 = exits8-exits7\n",
      "where exits7 != 'NaN'::float\n",
      "and exits8 != 'NaN'::float;\n",
      "\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in1 = entries2-entries1\n",
      "where entries1 != 'NaN'::float\n",
      "and entries2 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in2 = entries3-entries2\n",
      "where entries2 != 'NaN'::float\n",
      "and entries3 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in3 = entries4-entries3\n",
      "where entries3 != 'NaN'::float\n",
      "and entries4 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in4 = entries5-entries4\n",
      "where entries4 != 'NaN'::float\n",
      "and entries5 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in5 = entries6-entries5\n",
      "where entries5 != 'NaN'::float\n",
      "and entries6 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in6 = entries7-entries6\n",
      "where entries6 != 'NaN'::float\n",
      "and entries7 != 'NaN'::float;\n",
      "\n",
      "update sub_turn_stiles\n",
      "set in7 = entries8-entries7\n",
      "where entries7 != 'NaN'::float\n",
      "and entries8 != 'NaN'::float;\n",
      "\n",
      "\n",
      "alter table sub_turn_stiles \n",
      "    add column in_all double precision,\n",
      "    add column out_all double precision;\n",
      "update sub_turn_stiles\n",
      "set in_all = (select sum(s) from unnest(array[in1,in2,in3,in4,in5,in6,in7]) s);\n",
      "update sub_turn_stiles\n",
      "set out_all = (select sum(s) from unnest(array[out1,out2,out3,out4,out5,out6,out7]) s);\n",
      "\"\"\")"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# NEED to consolidate turn_stile data"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# turn_stile data with missing station name -- SMALL ADJUSTMENTS NEEDED\n",
      "cmd=\"\"\" select distinct unit,c_a from sub_turn_stiles \n",
      "        where station is null order by unit;\"\"\"\n",
      "pd.read_sql(cmd,engine)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# turn_stile data analysis:\n",
      "\n",
      "# general data used herein\n",
      "datetime_cols = ['datetime'+str(i) for i in range(1,9)]\n",
      "desc_cols = ['desc'+str(i) for i in range(1,9)]\n",
      "entry_cols = ['entries'+str(i) for i in range(1,9)]\n",
      "exit_cols = ['exits'+str(i) for i in range(1,9)]\n",
      "in_cols = ['in'+str(i) for i in range(1,9)]\n",
      "out_cols = ['out'+str(i) for i in range(1,9)]\n",
      "agg_cols = ['in_all','out_all']\n",
      "other_cols = ['index','lat','lon','id','geom']\n",
      "\n",
      "# 1. this shows there are multiple entries per station, i.e., multiple turn stiles\n",
      "cmd =   \"\"\"\n",
      "        select * from sub_turn_stiles \n",
      "        where out_all is not null\n",
      "        and station = '34 ST-HERALD SQ'\n",
      "        AND extract(hour from datetime1) = 4\n",
      "        AND extract(day from datetime1) = 29\n",
      "        order by out_all desc;\n",
      "        \"\"\"\n",
      "\n",
      "# 2. this shows there are multiple rows even when {c_a,unit,scp,datetime1} are same\n",
      "cmd =   \"\"\"\n",
      "        select * from sub_turn_stiles \n",
      "        where out_all is not null\n",
      "        and station = '34 ST-HERALD SQ'\n",
      "        AND scp = '00-00-00'\n",
      "        order by c_a,unit,datetime1 asc;\n",
      "        \"\"\"\n",
      "dropCols = desc_cols + entry_cols + exit_cols + in_cols + out_cols + other_cols"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0
      ],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3. this shows the door is open for people leaving during rush hour... (see datetime6-7)\n",
      "#        and possibly explains why multiple rows\n",
      "cmd =   \"\"\"\n",
      "        select * from sub_turn_stiles \n",
      "        where out_all is not null\n",
      "        and station = '34 ST-HERALD SQ'\n",
      "        AND scp = '00-00-00'\n",
      "        AND datetime1 = '2014-09-28 09:00:00-04:00';\n",
      "        \"\"\"\n",
      "# dropCols = desc_cols + entry_cols + exit_cols + in_cols + out_cols + other_cols\n",
      "pd.read_sql(cmd,engine)#.drop(dropCols,axis=1)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [],
      "run_control": {
       "read_only": false
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}